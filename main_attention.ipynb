{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aa1248d-3edc-4c72-98e7-313fc1260e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4cb328-21bf-4afc-b5fc-92e23a31d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset from https://www.kaggle.com/datasets/saurabhshahane/electricity-load-forecasting\n",
    "df = pd.read_csv('kaggle_electricity_load_forecasting_train.csv')\n",
    "df = df.set_index('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38d422b6-ff7a-4a29-b068-7bea4f4ce7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output = np.array(df['nat_demand']).reshape(-1, 1)\n",
    "data_input = np.array(df[['T2M_toc', 'QV2M_toc','TQL_toc','W2M_toc']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e64234d2-0ce5-496e-91cc-d742666b2c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output = torch.Tensor(data_output).cuda()\n",
    "data_input = torch.Tensor(data_input).cuda()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_input, data_output, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6f7d0e8-0c3f-4cad-8074-1200b4ad9b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionNet(nn.Module):\n",
    "    def __init__(self, inp_size, out_size, linear_size=36):\n",
    "        super(AttentionNet, self).__init__()\n",
    "\n",
    "        self.inp_size = inp_size\n",
    "        self.linear_size = linear_size\n",
    "        self.out_size = out_size\n",
    "        \n",
    "        self.inp_lin = nn.Linear(self.inp_size, self.linear_size)\n",
    "        self.lin1 = nn.Linear(self.linear_size, self.linear_size)\n",
    "        self.lin2 = nn.Linear(self.linear_size, self.linear_size)\n",
    "        self.out_lin = nn.Linear(self.linear_size, self.out_size)\n",
    "    def forward(self, x):\n",
    "        x = self.inp_lin(x)\n",
    "        x1 = F.relu(self.lin1(x))\n",
    "        x2 = F.relu(self.lin2(x))\n",
    "        temp = torch.matmul(x1, torch.matmul(x2.transpose(-2, -1), x2))\n",
    "        x = self.out_lin(temp)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DLFTNet(nn.Module):\n",
    "    def __init__(self, inp_size, out_size, linear_size=36):\n",
    "        super(DLFTNet, self).__init__()\n",
    "\n",
    "        self.inp_size = inp_size\n",
    "        self.linear_size = linear_size\n",
    "        self.out_size = out_size\n",
    "        \n",
    "        self.inp_lin = nn.Linear(self.inp_size, self.linear_size)\n",
    "        self.lin1 = nn.Linear(self.linear_size, self.linear_size)\n",
    "        self.out_lin = nn.Linear(self.linear_size ** 2, self.out_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.inp_lin(x)\n",
    "        x1 = torch.fft.fft(x).real.view(-1, x.shape[1], 1)\n",
    "        x2 = F.relu(self.lin1(x).view(-1, 1, x.shape[1]))\n",
    "        temp = torch.matmul(x1, x2).reshape(-1, x.shape[1] ** 2)\n",
    "        x = self.out_lin(temp)\n",
    "        return x\n",
    "\n",
    "class MLPNet(nn.Module):\n",
    "    def __init__(self, inp_size, out_size, freq_domain=None, linear_size=36):\n",
    "        super(MLPNet, self).__init__()\n",
    "\n",
    "        self.inp_size = inp_size\n",
    "        self.linear_size = linear_size\n",
    "        self.out_size = out_size\n",
    "        self.freq_domain = freq_domain\n",
    "        \n",
    "        self.inp_lin = nn.Linear(self.inp_size, self.linear_size)\n",
    "        self.lin1 = nn.Linear(self.linear_size, self.linear_size)\n",
    "        self.out_lin = nn.Linear(self.linear_size, self.out_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.inp_lin(x)\n",
    "        x1 = F.relu(self.lin1(x))\n",
    "        x = self.out_lin(x1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac9e192b-f58d-43db-b56d-2d6ab98239d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flyin\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1181.97119140625\n",
      "100 1177.33447265625\n",
      "200 1171.414794921875\n",
      "300 1163.2901611328125\n",
      "400 1151.924560546875\n",
      "500 1136.311279296875\n",
      "600 1115.4874267578125\n",
      "700 1088.7666015625\n",
      "800 1055.5067138671875\n",
      "900 1015.1172485351562\n",
      "1000 967.150146484375\n",
      "1100 911.2005004882812\n",
      "1200 846.8927001953125\n",
      "1300 773.8929443359375\n",
      "1400 691.8914184570312\n",
      "1500 600.6033935546875\n",
      "1600 500.0847473144531\n",
      "1700 394.53973388671875\n",
      "1800 299.57269287109375\n",
      "1900 234.61572265625\n",
      "2000 202.42921447753906\n",
      "2100 189.1259307861328\n",
      "2200 183.89242553710938\n",
      "2300 181.16310119628906\n",
      "2400 179.09420776367188\n",
      "2500 177.16004943847656\n",
      "2600 175.23635864257812\n",
      "2700 173.29843139648438\n",
      "2800 171.34446716308594\n",
      "2900 169.37982177734375\n",
      "3000 167.4129638671875\n",
      "3100 165.45407104492188\n",
      "3200 163.5090789794922\n",
      "3300 161.59129333496094\n",
      "3400 159.7122802734375\n",
      "3500 157.85797119140625\n",
      "3600 156.04156494140625\n",
      "3700 154.26397705078125\n",
      "3800 152.5464324951172\n",
      "3900 150.9071044921875\n",
      "4000 149.33517456054688\n",
      "4100 147.8204803466797\n",
      "4200 146.3750457763672\n",
      "4300 144.99822998046875\n",
      "4400 143.7020721435547\n",
      "4500 142.47637939453125\n",
      "4600 141.3231964111328\n",
      "4700 140.2449951171875\n",
      "4800 139.2395782470703\n",
      "4900 138.30799865722656\n",
      "5000 137.4476776123047\n",
      "5100 136.66921997070312\n",
      "5200 135.96206665039062\n",
      "5300 135.32833862304688\n",
      "5400 134.76690673828125\n",
      "5500 134.2655029296875\n",
      "5600 133.82264709472656\n",
      "5700 133.4313507080078\n",
      "5800 133.08421325683594\n",
      "5900 132.77267456054688\n",
      "6000 132.50164794921875\n",
      "6100 132.26991271972656\n",
      "6200 132.07369995117188\n",
      "6300 131.90911865234375\n",
      "6400 131.77195739746094\n",
      "6500 131.65635681152344\n",
      "6600 131.56338500976562\n",
      "6700 131.48878479003906\n",
      "6800 131.43077087402344\n",
      "6900 131.38528442382812\n",
      "7000 131.3486328125\n",
      "7100 131.31846618652344\n",
      "7200 131.29440307617188\n",
      "7300 131.27420043945312\n",
      "7400 131.25657653808594\n",
      "7500 131.2406768798828\n",
      "7600 131.2254638671875\n",
      "7700 131.21090698242188\n",
      "7800 131.19677734375\n",
      "7900 131.18296813964844\n",
      "8000 131.16912841796875\n",
      "8100 131.15516662597656\n",
      "8200 131.1410369873047\n",
      "8300 131.1266632080078\n",
      "8400 131.11216735839844\n",
      "8500 131.0974578857422\n",
      "8600 131.08253479003906\n",
      "8700 131.06741333007812\n",
      "8800 131.0520782470703\n",
      "8900 131.03659057617188\n",
      "9000 131.02090454101562\n",
      "9100 131.0050506591797\n",
      "9200 130.98898315429688\n",
      "9300 130.9727783203125\n",
      "9400 130.9564208984375\n",
      "9500 130.93988037109375\n",
      "9600 130.92318725585938\n",
      "9700 130.90634155273438\n",
      "9800 130.88931274414062\n",
      "9900 130.87217712402344\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m out \u001b[38;5;241m=\u001b[39m net(X_test)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     15\u001b[0m cpu_y_test \u001b[38;5;241m=\u001b[39m y_test\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mroot_mean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:572\u001b[0m, in \u001b[0;36mroot_mean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    514\u001b[0m     {\n\u001b[0;32m    515\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    524\u001b[0m ):\n\u001b[0;32m    525\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Root mean squared error regression loss.\u001b[39;00m\n\u001b[0;32m    526\u001b[0m \n\u001b[0;32m    527\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;124;03m    0.822...\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\n\u001b[1;32m--> 572\u001b[0m         \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraw_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m     )\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(multioutput, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    578\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m multioutput \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:497\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[0;32m    493\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[0;32m    494\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[0;32m    495\u001b[0m         )\n\u001b[1;32m--> 497\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    501\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:103\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m--> 103\u001b[0m y_true \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:997\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    995\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 997\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1001\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:521\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    519\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 521\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\_tensor.py:1062\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1062\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "net = MLPNet(4, 1).cuda()\n",
    "opti = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
    "loss = torch.nn.L1Loss().cuda()\n",
    "\n",
    "for i in range(0, 10000) :\n",
    "    opti.zero_grad()\n",
    "    out = net(X_train)\n",
    "    l = loss(out, y_train)\n",
    "    l.backward()\n",
    "    opti.step()\n",
    "    if i % 100 == 0 :\n",
    "        print(i, l.item())\n",
    "\n",
    "out = net(X_test).detach().cpu().numpy()\n",
    "cpu_y_test = y_test.detach().cpu().numpy()\n",
    "print(root_mean_squared_error(cpu_y_test, out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fd3772-d284-4c1c-80bb-cde90d66791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = AttentionNet(4, 1).cuda()\n",
    "opti = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
    "loss = torch.nn.L1Loss().cuda()\n",
    "\n",
    "for i in range(0, 10000) :\n",
    "    opti.zero_grad()\n",
    "    out = net(X_train)\n",
    "    l = loss(out, y_train)\n",
    "    l.backward()\n",
    "    opti.step()\n",
    "    if i % 100 == 0 :\n",
    "        print(i, l.item())\n",
    "\n",
    "out = net(X_test).detach().cpu().numpy()\n",
    "cpu_y_test = y_test.detach().cpu().numpy()\n",
    "print(root_mean_squared_error(cpu_y_test, out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4502bd62-e4ee-4316-b083-cbe6d19d5ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DLFTNet(4, 1).cuda()\n",
    "opti = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
    "loss = torch.nn.L1Loss().cuda()\n",
    "\n",
    "for i in range(0, 10000) :\n",
    "    opti.zero_grad()\n",
    "    out = net(X_train)\n",
    "    l = loss(out, y_train)\n",
    "    l.backward()\n",
    "    opti.step()\n",
    "    if i % 100 == 0 :\n",
    "        print(i, l.item())\n",
    "\n",
    "out = net(X_test).detach().cpu().numpy()\n",
    "cpu_y_test = y_test.detach().cpu().numpy()\n",
    "print(root_mean_squared_error(cpu_y_test, out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
